[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "My demo notebook",
    "section": "",
    "text": "Preface\nHello, welcome to my demo notebook. The purpose of this notebook is to log ideas I’ve explored. It’ll be useful for me, and hopefully, also for you!",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "intro.html",
    "href": "intro.html",
    "title": "1  Introduction",
    "section": "",
    "text": "This is a book created from markdown and executable code.\nSee Knuth (1984) for additional discussion of literate programming.\n\n1 + 1\n\n[1] 2\n\n\n\n\n\n\nKnuth, Donald E. 1984. “Literate Programming.” Comput. J. 27 (2): 97–111. https://doi.org/10.1093/comjnl/27.2.97.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "summary.html",
    "href": "summary.html",
    "title": "2  Summary",
    "section": "",
    "text": "In summary, this book has no content whatsoever.\n\n1 + 1\n\n[1] 2",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Summary</span>"
    ]
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Knuth, Donald E. 1984. “Literate Programming.” Comput.\nJ. 27 (2): 97–111. https://doi.org/10.1093/comjnl/27.2.97.",
    "crumbs": [
      "References"
    ]
  },
  {
    "objectID": "08_causal_inference_simulations.html",
    "href": "08_causal_inference_simulations.html",
    "title": "1  Title: Causal diagram simulations",
    "section": "",
    "text": "2 Load libraries\nlibrary(tidyverse) # for data wrangling\nlibrary(gtsummary) # for formatting model outputs into a nice html table\nlibrary(DiagrammeR) # for drawing dags \nlibrary(webshot2) #to help render doc",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Title: Causal diagram simulations</span>"
    ]
  },
  {
    "objectID": "08_causal_inference_simulations.html#chain-in-a-dag",
    "href": "08_causal_inference_simulations.html#chain-in-a-dag",
    "title": "1  Title: Causal diagram simulations",
    "section": "3.1 Chain in a DAG",
    "text": "3.1 Chain in a DAG\nHere is a chain, where B is a mediator. Mediators should not be conditioned on because it will limit the association between A and C.\n\nmermaid(\"graph LR\n        A--&gt;B\n        B--&gt;C\")",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Title: Causal diagram simulations</span>"
    ]
  },
  {
    "objectID": "08_causal_inference_simulations.html#colliders-in-a-dag",
    "href": "08_causal_inference_simulations.html#colliders-in-a-dag",
    "title": "1  Title: Causal diagram simulations",
    "section": "3.2 Colliders in a DAG",
    "text": "3.2 Colliders in a DAG\nHere is a collider, where C is a collider. Colliders should not be conditioned on because there will be a spurious association between a and b.\n\nmermaid(\"graph TD\n        A--&gt;C\n        B--&gt;C\")",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Title: Causal diagram simulations</span>"
    ]
  },
  {
    "objectID": "08_causal_inference_simulations.html#confounders-in-a-dag",
    "href": "08_causal_inference_simulations.html#confounders-in-a-dag",
    "title": "1  Title: Causal diagram simulations",
    "section": "3.3 Confounders in a DAG",
    "text": "3.3 Confounders in a DAG\nHere is a confounder, where B is a confound. Confounders SHOULD be conditioned on.\n\nmermaid(\"graph LR\n        A--&gt;C\n        B--&gt;A\n        B--&gt;C\")",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Title: Causal diagram simulations</span>"
    ]
  },
  {
    "objectID": "08_causal_inference_simulations.html#changing-the-mediator-to-a-categorical-variable-to-visualize",
    "href": "08_causal_inference_simulations.html#changing-the-mediator-to-a-categorical-variable-to-visualize",
    "title": "1  Title: Causal diagram simulations",
    "section": "4.1 Changing the mediator to a categorical variable to visualize",
    "text": "4.1 Changing the mediator to a categorical variable to visualize\n\n# try to set b as a categorical variable \na&lt;-rnorm(n=100,mean=50,sd=5)\nb&lt;-if_else(a&lt;50,0,1)\nc&lt;-b+rnorm(n=100,mean=0,sd=1)\n\n\n\nmod2.11&lt;-lm(c~a+b)\nmod2.11|&gt;\n  tbl_regression()\n\n\n\n\n\n\n\nCharacteristic\nBeta\n95% CI\np-value\n\n\n\n\na\n0.02\n-0.05, 0.09\n0.5\n\n\nb\n1.1\n0.49, 1.7\n&lt;0.001\n\n\n\nAbbreviation: CI = Confidence Interval\n\n\n\n\n\n\n\n#grouping by b (mediator) disrupts the correlation by a nd c\nggplot(data=tibble(a,c),aes(x=a,y=c,group=factor(b)))+geom_point()+stat_smooth(method=\"lm\")\n\n`geom_smooth()` using formula = 'y ~ x'",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Title: Causal diagram simulations</span>"
    ]
  },
  {
    "objectID": "08_causal_inference_simulations.html#more-complicated-collider-case",
    "href": "08_causal_inference_simulations.html#more-complicated-collider-case",
    "title": "1  Title: Causal diagram simulations",
    "section": "5.1 More complicated collider case",
    "text": "5.1 More complicated collider case\nwhere:\n\nmermaid(\"graph TD\n        A--&gt;B\n        A--&gt;C\n        B--&gt;C\")\n\n\n\n\n\n\\[a \\sim Normal(50,5)\\]\n\\[b \\sim a+\\epsilon\\]\n\\[c \\sim a+b+\\epsilon\\]\nRandom error: \\(\\epsilon \\sim Normal(0,5)\\)\nNote: It is expected for a and b to have 1:1 relationship\n\na&lt;-rnorm(n=100,mean=50,sd=5)\nb&lt;-a+rnorm(n=100,mean=0,sd=5) #b is a function of a + random error \nc&lt;-a+b+rnorm(n=100,mean=0,sd=5) # c is a fucntion of a and b with random error\n\n#fit a model between a-&gt; b\n#there is a 1:1 relationship\nmod3.1&lt;-lm(b~a)\nmod3.1|&gt;\n  tbl_regression()\n\n\n\n\n\n\n\nCharacteristic\nBeta\n95% CI\np-value\n\n\n\n\na\n0.94\n0.72, 1.2\n&lt;0.001\n\n\n\nAbbreviation: CI = Confidence Interval\n\n\n\n\n\n\n\n#There is no association between A and B. \n\n#fit a model with a collider c\nmod4.1&lt;-lm(b~a+c)\nmod4.1|&gt;\n  tbl_regression()\n\n\n\n\n\n\n\nCharacteristic\nBeta\n95% CI\np-value\n\n\n\n\na\n-0.15\n-0.38, 0.08\n0.2\n\n\nc\n0.54\n0.45, 0.63\n&lt;0.001\n\n\n\nAbbreviation: CI = Confidence Interval\n\n\n\n\n\n\n\n\nNote that the association between a and b is negative when conditioning on c, the collider (above) and when we do it here when a and b are correlated, the correlation breaks.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Title: Causal diagram simulations</span>"
    ]
  },
  {
    "objectID": "14_simulating_95CI_frequentist.html",
    "href": "14_simulating_95CI_frequentist.html",
    "title": "3  Simulating 95% confidence intervals",
    "section": "",
    "text": "4 Load Libraries\n\nlibrary(tidyverse)\n\n\n\n5 Simulating 95% frequentist confidence intervals\nA good explanation here:\nA 95% confidence interval is constructed such that if the model assumptions are correct and if you were to hypothetically repeat the experiment or sampling many many times, 95% of the intervals constructed would contain the true value of the parameter.\nMy own words: The 95% confidence interval is when the true parameter is contained within the interval 95% of the time from constructing the 95% confidence interval from repeated experiments under the assumption of a correct model.\nLet’s gain intuition by what this means:\n\nSimulate data and do it a bunch of times\n\nThen calculate 95% confidence interval with say a t-test\nDetermine how many times the true parameter (which we set in step 1) is in between the confidence intervals\n\n\n#1) simulate data \nsim&lt;-10000\n#dataset size\nn&lt;-100\n# sampel data with mean 10, sd =1 \nx&lt;-rnorm(n,mean=10,sd=1)\n#fit t.test ; grab lower and upper confidence interval\n#as.vector(c(t.test(x)$conf.int,t.test(x)$estimate))\n\n\n## now simulate across sim \n\n#for loop is prob best \n#prep dataset\n#d&lt;-tibble(lower=rep(0,sim),upper=rep(0,sim),mean=rep(0,sim))\nd&lt;-array(0,dim=c(sim,2))\n\nfor (i in 1:sim){\n  x&lt;-rnorm(n,mean=10,sd=1)\n  d[i,]&lt;-as.vector(c(t.test(x)$conf.int))\n}\n\n\n#head(d)\nd&lt;-data.frame(d)\nnames(d)&lt;-c(\"lower\",\"upper\")\nknitr::kable(head(d))\n\n\n\n\nlower\nupper\n\n\n\n\n9.864426\n10.24753\n\n\n9.919894\n10.28799\n\n\n9.776263\n10.12107\n\n\n9.803304\n10.17358\n\n\n9.815622\n10.19801\n\n\n9.749086\n10.14565\n\n\n\n\n#count how many times the lower and upper confidence interval is below true value of 10\nd&lt;-d|&gt;\n  mutate(out=1*(lower&lt;10 & upper&gt;10))\nmean(d$out)\n\n[1] 0.9518\n\n#cases where confidence interval is does not include true parameter \nd|&gt;\n  filter(out==0)|&gt;\n  head()\n\n      lower     upper out\n1 10.018179 10.417733   0\n2 10.018316 10.425242   0\n3  9.597978  9.976863   0\n4 10.038336 10.401601   0\n5  9.542640  9.984501   0\n6 10.000022 10.384590   0\n\n\nAdditional notes:\n\nCementing interpretation: When you have a single 95% CI on a single sample, it doesn’t mean, that the population mean belongs to this particular interval with a particular probability. If you were to repeat the experiment many many times and calculate this interval on each fo the samples, then 95% of the repeated samples would have the true population mean.\n\n\n6 Session info\n\nsessionInfo()\n\nR version 4.5.0 (2025-04-11 ucrt)\nPlatform: x86_64-w64-mingw32/x64\nRunning under: Windows 11 x64 (build 26100)\n\nMatrix products: default\n  LAPACK version 3.12.1\n\nlocale:\n[1] LC_COLLATE=English_United States.utf8 \n[2] LC_CTYPE=English_United States.utf8   \n[3] LC_MONETARY=English_United States.utf8\n[4] LC_NUMERIC=C                          \n[5] LC_TIME=English_United States.utf8    \n\ntime zone: America/New_York\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nother attached packages:\n [1] lubridate_1.9.4 forcats_1.0.0   stringr_1.5.1   dplyr_1.1.4    \n [5] purrr_1.0.4     readr_2.1.5     tidyr_1.3.1     tibble_3.2.1   \n [9] ggplot2_3.5.2   tidyverse_2.0.0\n\nloaded via a namespace (and not attached):\n [1] gtable_0.3.6      jsonlite_2.0.0    compiler_4.5.0    tidyselect_1.2.1 \n [5] scales_1.3.0      yaml_2.3.10       fastmap_1.2.0     R6_2.6.1         \n [9] generics_0.1.3    knitr_1.50        htmlwidgets_1.6.4 munsell_0.5.1    \n[13] pillar_1.10.2     tzdb_0.5.0        rlang_1.1.6       stringi_1.8.7    \n[17] xfun_0.52         timechange_0.3.0  cli_3.6.4         withr_3.0.2      \n[21] magrittr_2.0.3    digest_0.6.37     grid_4.5.0        rstudioapi_0.17.1\n[25] hms_1.1.3         lifecycle_1.0.4   vctrs_0.6.5       evaluate_1.0.3   \n[29] glue_1.8.0        colorspace_2.1-1  rmarkdown_2.29    tools_4.5.0      \n[33] pkgconfig_2.0.3   htmltools_0.5.8.1",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Simulating 95% confidence intervals</span>"
    ]
  },
  {
    "objectID": "13_Bayesian_inference_Beta_priors_JingchenHu_lab1.html",
    "href": "13_Bayesian_inference_Beta_priors_JingchenHu_lab1.html",
    "title": "2  Lab1: Bayesian inference with beta priors, Jingchen Hu",
    "section": "",
    "text": "3 Intro\nThis is a lab by a professor, Jinchen Hu, which goes over Bayesian inference with beta priors.\n\n\n4 Load libraries\n\nlibrary(tidyverse)\nlibrary(ProbBayes)\n\n\n\n5 Posterior predictive checking\n\nS&lt;-10000 # number of simulations\na&lt;-3.06 # a in beta(a,b)\nb&lt;-2.56 # b in beta(a,b)\nn&lt;-20 # number of trials\ny&lt;-12 # number of successes \n\nnewy=as.data.frame(rep(NA,S))\nnames(newy)=c(\"y\")\n\nset.seed(123)\nfor (s in 1:S){\n  pred_p_sim&lt;-rbeta(1, a+y, b+n-y) # step 1 ; get posterior param\n  pred_y_sim&lt;-rbinom(1,n,pred_p_sim) # step 2; based on param, predict outcome-&gt; # of successes\n  newy[s,]=pred_y_sim\n}\nknitr::kable(head(newy))\n\n\n\n\ny\n\n\n\n\n14\n\n\n13\n\n\n8\n\n\n12\n\n\n14\n\n\n5\n\n\n\n\n#how i would write the simluation\n\ndat&lt;-tibble(pred_p=rbeta(S,a+y,b+n-y))|&gt;\n  rowwise()|&gt;\n  mutate(pred_y=rbinom(1,n,pred_p))\n\nsum(dat$pred_y&gt;=5&dat$pred_y&lt;=15)/S\n\n[1] 0.8943\n\n#dat$pred_y&lt;-rbinom(1000,n,dat$pred_p)\nggplot(data=dat,aes(pred_y))+geom_density()+scale_x_continuous(breaks=seq(0,20,1),labels=seq(0,20,1))\n\n\n\n\n\n\n\n\n\n\n6 Let’s try to simulate a situation with mismatched prior with the data\n\nbeta_draw(c(3.06,2.56)) #prior fromp revious section \n\n\n\n\n\n\n\nbeta_draw(c(0.5,5)) #this looks liek a good prior to mess up the data \n\n\n\n\n\n\n\ns&lt;-10000\nn&lt;-20 # trials\ny&lt;-12 #successes\na&lt;-.5\nb&lt;-5\n\ndat2&lt;-tibble(pred_p=rbeta(S,a+y,b+n-y))|&gt;\n  rowwise()|&gt;\n  mutate(pred_y=rbinom(1,n,pred_p))\n\n# model check : how often pr(y &gt; ypred|y)\nsum(y&gt;dat2$pred_y)/S # how often collected data above posterior prediction\n\n[1] 0.7158\n\n1-sum(y&gt;dat2$pred_y)/S #how often collected data below posterior prediction\n\n[1] 0.2842\n\n#draw posterior\nbeta_prior_post(c(.5,5),c(a+y,b+n-y))\n\n\n\n\n\n\n\n\n\n\n7 Session info\n\nbeta_draw(c(.3,.7)) \n\n\n\n\n\n\n\nsessionInfo()\n\nR version 4.5.0 (2025-04-11 ucrt)\nPlatform: x86_64-w64-mingw32/x64\nRunning under: Windows 11 x64 (build 26100)\n\nMatrix products: default\n  LAPACK version 3.12.1\n\nlocale:\n[1] LC_COLLATE=English_United States.utf8 \n[2] LC_CTYPE=English_United States.utf8   \n[3] LC_MONETARY=English_United States.utf8\n[4] LC_NUMERIC=C                          \n[5] LC_TIME=English_United States.utf8    \n\ntime zone: America/New_York\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nother attached packages:\n [1] ProbBayes_1.1     shiny_1.10.0      gridExtra_2.3     LearnBayes_2.15.1\n [5] lubridate_1.9.4   forcats_1.0.0     stringr_1.5.1     dplyr_1.1.4      \n [9] purrr_1.0.4       readr_2.1.5       tidyr_1.3.1       tibble_3.2.1     \n[13] ggplot2_3.5.2     tidyverse_2.0.0  \n\nloaded via a namespace (and not attached):\n [1] generics_0.1.3    stringi_1.8.7     hms_1.1.3         digest_0.6.37    \n [5] magrittr_2.0.3    evaluate_1.0.3    grid_4.5.0        timechange_0.3.0 \n [9] fastmap_1.2.0     jsonlite_2.0.0    promises_1.3.2    scales_1.3.0     \n[13] cli_3.6.4         rlang_1.1.6       munsell_0.5.1     withr_3.0.2      \n[17] yaml_2.3.10       tools_4.5.0       tzdb_0.5.0        colorspace_2.1-1 \n[21] httpuv_1.6.16     vctrs_0.6.5       R6_2.6.1          mime_0.13        \n[25] lifecycle_1.0.4   htmlwidgets_1.6.4 pkgconfig_2.0.3   pillar_1.10.2    \n[29] later_1.4.2       gtable_0.3.6      glue_1.8.0        Rcpp_1.0.14      \n[33] xfun_0.52         tidyselect_1.2.1  rstudioapi_0.17.1 knitr_1.50       \n[37] farver_2.1.2      xtable_1.8-4      htmltools_0.5.8.1 rmarkdown_2.29   \n[41] labeling_0.4.3    compiler_4.5.0",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Lab1: Bayesian inference with beta priors, Jingchen Hu</span>"
    ]
  }
]