{
  "hash": "ec1c5ac25fc2ad1b12496c6c765b6bd0",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Bayesian inference in discrete case\"\nauthor: \"Andrew D. Nguyen\"\nformat: html\ntoc: true\neditor: visual\neditor_options: \n  chunk_output_type: console\n---\n\nDate: 2025-04-19\n\n# Load libraries\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\n```\n:::\n\n\n# Bayesian inference in discrete case: simple example\n\nThe scenario (taken from Dr. Jingchen (Monika) Hu from [youtube, S22 Math 347 course](https://www.youtube.com/watch?v=OOqDyAGp2y4&list=PL_lWxa4iVNt2GBPOVZMVKD4jYl9Q7hs2K&index=8)): A chinese food restaurant owner wants to increase the business profits and wants to know when people prefer to come into her restaurant. Specifically, she is interested in how often people chose Friday. So, Friday = \"success\", and all other days are considered \"failures\". She wants to use a Bayesian approach to estimate the probability that patrons will believe Friday is their favorite day to eat.\n\n## Steps\n\nShe wants to use a Bayesian approach and involves the following steps:\n\n1.  **Set up the prior expectations of success** $\\pi(p)$ or $\\pi(success)$\n\n2.  **Collect data and estimate the likelihood** -\\> use binomial distribution\n\nLikelihood of p and Binomial probability mass function (pmf):$$\\pi(y|p_{i})=L(p_{i})=P(Y = y) = \\binom{n}{y} p^y (1-p)^{n-y}$$\n\nAssumptions of binomial experiment:\n\n1.  repeating same task/trial many times\\\n2.  on each trial, 2 possible outcomes: \"success\" or \"failure\"\\\n3.  Prob of success, p, same for each trial\\\n4.  Results of outcomes from different trials are independent\n\nÂ \n\n3.  **Apply Baye's rule**\n\nBayes rule: $$\\pi(p_{i}| y) = \\frac{\\pi(y|p_{i}) \\times \\pi(p_{i})}{\\pi(y)} $$\n\n$$\\pi(y) = \\sum_{j} \\pi(p_{j}\\times L(p_{j})) $$\n\nThe denominator gives the marginal distribution of the observation $y$ by the law of total probability.\n\n## Set up prior $\\pi(p)$\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#probabilities of success to consider\np<-seq(.3,.8,.1)\n#p\n\n#probabilities for each of p \nprior<-c(.125,.125,.25,.25,.125,.125)\n\nd<-tibble(prior,p)\n\nggplot(d,aes(x=p,y=prior))+geom_bar(stat=\"identity\")+theme_bw()+scale_x_continuous(limits=c(0,1),breaks=seq(0,1,.1),labels=seq(0,1,.1))+ylab(\"prior probability\")\n```\n\n::: {.cell-output-display}\n![](12_Bayesian_inference_discrete_simple_case_files/figure-pdf/prior-1.pdf){fig-pos='H'}\n:::\n:::\n\n\n## Calculate likelihood -binomial\n\nShe surveyed 20 patrons and 12 chose Friday. So this looks like\n\n$$L(p_{i}) = \\binom{20}{12}p^{12}\\times (1-p)^{20-12}$$\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#use the density binomial function , dbinom()\nd$likelihood<-dbinom(x=12,size=20,prob=d$p)\nknitr::kable(d)\n```\n\n::: {.cell-output-display}\n\n\n| prior|   p| likelihood|\n|-----:|---:|----------:|\n| 0.125| 0.3|  0.0038593|\n| 0.125| 0.4|  0.0354974|\n| 0.250| 0.5|  0.1201344|\n| 0.250| 0.6|  0.1797058|\n| 0.125| 0.7|  0.1143967|\n| 0.125| 0.8|  0.0221609|\n\n\n:::\n:::\n\n\n## Apply Baye's rule and calculate the posterior probability ($\\pi(p_{i}|y)$)\n\n$\\pi(p_{i}|y)$ is the posterior probability of $p = p_{i}$ given the number of successes $y$.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nd$marg<-sum(d$prior*d$likelihood)\n\nd$posterior<-(d$prior*d$likelihood)/d$marg\n\n#plot table\nknitr::kable(d)\n```\n\n::: {.cell-output-display}\n\n\n| prior|   p| likelihood|      marg| posterior|\n|-----:|---:|----------:|---------:|---------:|\n| 0.125| 0.3|  0.0038593| 0.0969493| 0.0049759|\n| 0.125| 0.4|  0.0354974| 0.0969493| 0.0457680|\n| 0.250| 0.5|  0.1201344| 0.0969493| 0.3097865|\n| 0.250| 0.6|  0.1797058| 0.0969493| 0.4634013|\n| 0.125| 0.7|  0.1143967| 0.0969493| 0.1474955|\n| 0.125| 0.8|  0.0221609| 0.0969493| 0.0285728|\n\n\n:::\n\n```{.r .cell-code}\n#let's plot everything out \n#ggplot(d,aes(x=p,y=posterior))+geom_point()\n```\n:::\n\n\n### inferential question: What is the posterior prob that over half of the customers prefer to eat out on friday for dinner?\n\n\n::: {.cell}\n\n```{.r .cell-code}\nan<-d|>\n  filter(p>.5)|>\n  dplyr::summarise(oh=sum(posterior))\n```\n:::\n\n\n$Prob(p>0.5) =$ 0.639469613008657\n\n### Let's plot out the prior, likelihood, and posterior\n\nI'm going to normalize the likelihood function with 3x the max for plottig purposes.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nd$sl<-d$likelihood/(max(d$likelihood)*3)\n\nd2<-d|>\n  select(p,prior,sl,posterior)|>\n  pivot_longer(prior:posterior)|>\n  mutate(parameter=if_else(name==\"prior\",\"Prior\",if_else(name==\"sl\",\"Likelihood\",\"Posterior\")))\n\n\nggplot(d2,aes(x=p,y=value,colour=parameter))+geom_point()+geom_line(linewidth=1)+xlab(\"Probability\")+ylab(\"Density\")+theme_bw()+theme(legend.position=\"top\")+scale_colour_manual(name=\"\",values=c('#AA1E2D','#46A6B2','#18272F'))\n```\n\n::: {.cell-output-display}\n![](12_Bayesian_inference_discrete_simple_case_files/figure-pdf/unnamed-chunk-2-1.pdf){fig-pos='H'}\n:::\n:::\n\n\n# Sessioninfo\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsessionInfo()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nR version 4.5.0 (2025-04-11 ucrt)\nPlatform: x86_64-w64-mingw32/x64\nRunning under: Windows 11 x64 (build 26100)\n\nMatrix products: default\n  LAPACK version 3.12.1\n\nlocale:\n[1] LC_COLLATE=English_United States.utf8 \n[2] LC_CTYPE=English_United States.utf8   \n[3] LC_MONETARY=English_United States.utf8\n[4] LC_NUMERIC=C                          \n[5] LC_TIME=English_United States.utf8    \n\ntime zone: America/New_York\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nother attached packages:\n [1] lubridate_1.9.4 forcats_1.0.0   stringr_1.5.1   dplyr_1.1.4    \n [5] purrr_1.0.4     readr_2.1.5     tidyr_1.3.1     tibble_3.2.1   \n [9] ggplot2_3.5.2   tidyverse_2.0.0\n\nloaded via a namespace (and not attached):\n [1] gtable_0.3.6      jsonlite_2.0.0    compiler_4.5.0    tidyselect_1.2.1 \n [5] tinytex_0.57      scales_1.3.0      yaml_2.3.10       fastmap_1.2.0    \n [9] R6_2.6.1          labeling_0.4.3    generics_0.1.3    knitr_1.50       \n[13] munsell_0.5.1     pillar_1.10.2     tzdb_0.5.0        rlang_1.1.6      \n[17] stringi_1.8.7     xfun_0.52         timechange_0.3.0  cli_3.6.4        \n[21] withr_3.0.2       magrittr_2.0.3    digest_0.6.37     grid_4.5.0       \n[25] hms_1.1.3         lifecycle_1.0.4   vctrs_0.6.5       evaluate_1.0.3   \n[29] glue_1.8.0        farver_2.1.2      colorspace_2.1-1  rmarkdown_2.29   \n[33] tools_4.5.0       pkgconfig_2.0.3   htmltools_0.5.8.1\n```\n\n\n:::\n:::\n\n",
    "supporting": [
      "12_Bayesian_inference_discrete_simple_case_files\\figure-pdf"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {
      "knitr": [
        "{\"type\":\"list\",\"attributes\":{},\"value\":[]}"
      ]
    },
    "preserve": null,
    "postProcess": false
  }
}